{"timestamp": 1661316483.851894, "stored_source_code": "# Add description here\n#\n# *Note:* You can open this file as a notebook (JupyterLab: right-click on it in the side bar -> Open With -> Notebook)\n# Uncomment the next two lines to enable auto reloading for imported modules\n# %load_ext autoreload\n# %autoreload 2\n# For more info, see:\n# https://docs.ploomber.io/en/latest/user-guide/faq_index.html#auto-reloading-code-in-jupyter\n##NOTE necessary to ignore warnings for usable report.\nimport warnings\nfrom pathlib import Path\n\nfrom darts import TimeSeries\n\nfrom darts.dataprocessing import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score, KFold, RepeatedKFold, GridSearchCV\n\nfrom hydro_timeseries.darts_utils import backtest_minute_data\n\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nnp.set_printoptions(precision=3)\n\nimport pandas as pd\nfrom hydro_timeseries.plotting import *\nfrom hydro_timeseries.util import *\nimport statsmodels.api as sm\nfrom pmdarima import auto_arima\nfrom sklearn.metrics import mean_squared_error\nfrom datetime import timedelta\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# If this task has dependencies, declare them in the YAML spec and leave this\n# as None\nupstream = None\n\n# This is a placeholder, leave it as None\nproduct = None\n'''\nLoad data and split according to valid_from\nDrop last two days\n'''\n\ndata = load_timeseries_csv(upstream['run-tests']['data'])\ndata_daily = data.resample('D').mean()\ndata_hourly = data.resample('h').mean()\n\nplots_path = Path(plots_path)\ntsplot(data['2021-12-31':'2022-01-01']['Value'], do_plot_acf=False, filepath=plots_path / 'task_explanation.png')\ntsplot(data['Value'], do_plot_acf=False, filepath=plots_path / 'value.png')\n# target is loaded daily.\ntrain_until = pd.to_datetime(valid_from) - timedelta(days=1)\ntrain = data[:train_until]\nval = data[valid_from:]\n\n# NOTE drop NaN Values for the last two days\nval = val.dropna(axis = 0)\n'''\nPlot time series.\n15 minute - too much variance\ndaily mean - doable.\n'''\n\ntsplot(train.Value, label = 'Value, 15 min')\ntrain_daily = data_daily[:train_until]\nval_daily = data_daily[valid_from:]\n\ntsplot(train_daily.Value, label = 'Value daily')\n'''\nSingle day curve for max, min. \nTrue mean as a predictor\n'''\n\ntrain_daily_nonzero = train_daily[train_daily.Value != 0]\nmax_day = train_daily_nonzero.Value.idxmax().date()\nmin_day = train_daily_nonzero.Value.idxmin().date()\nmedian_mean = train_daily_nonzero.Value.median()\n\nmax_day_pred = train[max_day.isoformat()].Value.copy()\nmax_day_mean = np.mean(train[max_day.isoformat()].Value)\nmax_day_pred[:] = max_day_mean\n\nmin_day_pred = train[min_day.isoformat()].Value.copy()\nmin_day_mean = np.mean(train[min_day.isoformat()].Value)\nmin_day_pred[:] = min_day_mean\n\ntsplot(train[max_day.isoformat()].Value, y_pred=max_day_pred, label=f'Day curve for max daily mean, {max_day.isoformat()}, green predicted val')\ntsplot(train[min_day.isoformat()].Value, y_pred=min_day_pred, label=f'Day curve for min daily mean, {min_day.isoformat()}, green predicted val')\n'''\nTrue Daily mean as a predictor \n- not bad \n- 288 kw error on average. \n'''\n\ntrain['daily_true_mean'] = train.Value.resample('D').mean().reindex(train.index, method='ffill')\nresid_true_mean = (train.Value - train.daily_true_mean).values\n\nrmse_true_mean = np.sqrt(mean_squared_error(y_true=train.Value.values, y_pred=train.daily_true_mean.values))\nplot_residuals(resid_true_mean, title='Residuals: $y_{15}-y_{daily}$, predictor: true daily mean')\nprint(f'rmse_true_mean_daily = {rmse_true_mean}')\n'''\nTrue hourly mean: \n- rmse = 122 kw error\n'''\n\ntrain['hourly_true_mean'] = train.Value.resample('h').mean().reindex(train.index, method='ffill')\nresid_true_mean = (train.Value - train.hourly_true_mean).values\n\nrmse_true_mean = np.sqrt(mean_squared_error(y_true=train.Value.values, y_pred=train.hourly_true_mean.values))\nplot_residuals(resid_true_mean, title='Residuals: $y_{15}-y_{hourly}$, predictor: true hourly mean')\nprint(f'rmse_true_mean_hourly = {rmse_true_mean}')\n'''\n# Simple differencing d=1, check for stationarity\n\n\n## STATIONARITY \nA stationary time series is one whose properties do not depend on the time at which the series is observed.\n\nSome cases can be confusing \u2014 a time series with cyclic behaviour (but with no trend or seasonality) is stationary. This is because the cycles are not of a fixed length, so before we observe the series we cannot be sure where the peaks and troughs of the cycles will be.\n\nIn general, a stationary time series will have no predictable patterns in the long-term. Time plots will show the series to be roughly horizontal (although some cyclic behaviour is possible), with constant variance.\n\nAs well as looking at the time plot of the data, the ACF plot is also useful for identifying non-stationary time series. \nFor a stationary time series, the ACF will drop to zero relatively quickly, while the ACF of non-stationary data decreases slowly. \n'''\ndaily_1diff = train_daily.Value.diff(1).dropna()\ntsplot(daily_1diff, lags=15, label='Value diff = 1, \"Daily changes\"')\n\n# 7 day window\nadfuller_test(daily_1diff, window = 7)\n\nprint(f\"Daily Value summary, mean={train_daily.Value.describe()['mean']}\")\nprint(train_daily.Value.describe())\n\nprint(\"Daily Value changes summary\")\n# mean not in 0, slightly shifted.\nprint(daily_1diff.describe())\n'''\nAuto arma\n'''\nsm.tsa.arma_order_select_ic(daily_1diff.values, ic='bic', max_ar=3, max_ma=2)\n'''\ndebug\n'''\nprint(train_daily.Value.head())\n\nprint(train_daily.Value.tail())\n'''\narima (2,1,1)\nAIC, BIC - the lower the better\n'''\n\n\nmodel = sm.tsa.arima.ARIMA(train_daily.Value.values, order=(2,1,1), trend=None).fit(start_params=[0, 0, 0, 1])\nprint(model.summary())\n\ntsplot(model.resid, label = 'Residuals $y_t - \\hat{y}_t$', filepath=plots_path / 'arima_daily_1step.png')\n\n\nmodel.plot_diagnostics(figsize=(15,5))\nplt.show()\n# '''\n# Auto arima confirms (2,1,1) for daily.\n# '''\n#\n'''\nARIMA (2,1,1) rolling day ahead forecast\n'''\nfrom datetime import timedelta\nfrom datetime import date\n\nvalid_from_dt = date.fromisoformat(valid_from)\nall_means = data_daily.dropna(axis=0)\nall_means['Date'] = all_means.index.date\n\nval['arima_daily'] = -10000\nval['Date'] = pd.to_datetime(val.index.date)\ntraining_dates = [valid_from_dt - timedelta(days=1)]\nfor idx, val_date in enumerate(sorted(set(val.Date))):\n    date_ahead = val_date + timedelta(days = 1)\n\n    print(f'current day={val_date.date()} predicting day={date_ahead.date()} with last training date={training_dates[-1]}')\n    day_ahead = val[val.Date == date_ahead]\n\n    # for training only use D-1, D-2, D-3...\n    training_df = all_means[all_means.Date <= training_dates[-1]]\n    arima_daily = sm.tsa.arima.ARIMA(training_df.Value.values, order=(2, 1, 1), trend=None).fit()\n    pred = arima_daily.forecast(steps = 2)\n    day_ahead_arima = pred[1]\n\n    # fill dataframe with day ahead arima mean prediction\n    val.loc[val.Date == date_ahead, 'arima_daily'] = day_ahead_arima\n\n    # make a one day step\n    training_dates.append(val_date.date())\n\nbaseline_eval = val[val.arima_daily != -10000]\nprint(\"Value should not be -10000\")\nprint(baseline_eval.iloc[0])\n'''\nEvaluation of baseline for two step prediction\n\nrmse = 353 kw on average\n'''\nbaseline_eval[['Value', 'arima_daily']].plot(title='Hold out - arima day ahead mean')\nplt.show()\nbaseline_eval.loc[:, 'resid'] = baseline_eval.Value - baseline_eval.arima_daily\ntsplot(baseline_eval.resid, label='Hold out - day ahead arima residuals: $y_{t+1} - \\hat{y}_{t+1}$', filepath=plots_path / 'arima_daily_2step.png')\nbaseline_mse = np.sqrt(np.mean(baseline_eval.resid.values**2))\n\nsmape_hold_out = smape(baseline_eval.Value, baseline_eval.arima_daily)\n\nplot_residuals(baseline_eval.resid.values, title=f'Hold out - Residuals for day ahead ARIMA rmse={baseline_mse}')\nprint(f\"Baseline: Day ahead ARIMA(2,1,1) for two step prediction rmse={baseline_mse} & smape={smape_hold_out} on hold out\")\n'''\nDetrending and then explaining the seasonal + residual components using \nRF with cyclical variables + lagged residuals \n(NOTE: try longer trend: period = 30)\n'''\n# trend, seasonal, resid = seasonal_decompose_plot(data_daily.Value.dropna(axis=0), period=15)\ntrend, seasonal, resid = seasonal_decompose_plot(data_daily.Value.dropna(axis=0), period=7)\nselector = ~trend.isna()\ntrend = trend[selector]\nseasonal = seasonal[selector]\nresid = resid[selector]\n'''\n(5,1,1) for trend period=30\n(2,1,1) for trend if period not specified\n'''\n\ntrend_arima = auto_arima(trend,\n                          information_criterion='bic',\n                          trace = True,\n                          stepwise = True,\n                          random_state=random_seed,\n                          n_fits = 1000)\ntrend_arima = sm.tsa.arima.ARIMA(trend, order=(2,1,1), trend=None).fit()\nprint(trend_arima.summary())\ntrend_arima.plot_diagnostics(figsize=(15,5))\nplt.show()\nfrom darts.models import ARIMA\n#RMSE=356.87 MAE=253.67\n#arima = ARIMA(p=5, d=1, q=0, trend=None)>.fit(TimeSeries.from_series(train_daily['Value'].dropna()))\n\n#RMSE=353.14 MAE=253.41\n# arima = ARIMA(p=2, d=1, q=1, trend=None)\n\n# arima = ARIMA(p=5, d=1, q=0, trend=None).fit(TimeSeries.from_series(train_daily['Value'].dropna()))\narima = ARIMA(p=2, d=1, q=1, trend=None).fit(TimeSeries.from_series(train_daily['Value'].dropna()))\nbacktest, ts_eval, rmse, mae, mape = backtest_minute_data(arima,\n                   TimeSeries.from_series(data_daily['Value'].dropna()),\n                   data_df=data.dropna(), valid_from='2021-01-20',\n                   forecast_horizon=2, retrain=True,\n                   scaler=None)\n\nbt_df = backtest.pd_dataframe()\n\narima_true_resid = (data_daily['Value'] - bt_df['Value']).dropna()\ntsplot(arima_true_resid, label=\"new_target = Seasonal + resid\")\nnew_daily = arima_true_resid.to_frame('target')\nnew_daily['resid_lag2']=arima_true_resid.shift(2)\nnew_daily['arima'] = bt_df['Value']\nnew_daily['Value'] = data_daily['Value']\nnew_daily = (\n        new_daily\n        # .assign(hour = data.index.hour)\n        # .assign(day_of_month = data.index.day)\n        .assign(month = new_daily.index.month)\n        # .assign(day_of_week = data.index.dayofweek)\n        .assign(day_of_year = new_daily.index.day_of_year)\n        .assign(week_of_year = new_daily.index.week)\n        )\n\nnew_daily = generate_cyclical_features(new_daily, 'month', 12, 1)\nnew_daily = generate_cyclical_features(new_daily, 'week_of_year', 53, 1)\nnew_daily = generate_cyclical_features(new_daily, 'day_of_year', 366, 1)\nnew_daily = new_daily.dropna()\nprint(new_daily.head())\n\nfeatures = ['resid_lag2', 'sin_month', 'cos_month', 'sin_week_of_year',\n       'cos_week_of_year', 'sin_day_of_year', 'cos_day_of_year']\n\nX = new_daily[features][:pd.to_datetime(valid_from) - timedelta(days=1)]\ny = new_daily['target'][:pd.to_datetime(valid_from) - timedelta(days=1)].values.ravel()\n\nnew_daily_test = new_daily[pd.to_datetime(valid_from):]\ncv = RepeatedKFold(n_splits=4,n_repeats=2, random_state=random_seed)\nrf = RandomForestRegressor(random_state=random_seed)\nparam_grid = {\n    'n_estimators': list(range(50, 200, 20)),\n    'max_features': [None, 'sqrt'],\n    'max_depth' : [6, 7, 8, 10, 20, 30],\n    'min_samples_split' : [4, 8, 16],\n    'min_samples_leaf' : [4, 5, 6],\n}\n# CV_rf = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=-1, verbose=3, error_score=\"raise\")\n# CV_rf.fit(X, y)\n# print(CV_rf.best_params_)\n# print(CV_rf.best_score_)\n#\n# chosen_params = CV_rf.best_params_\nchosen_params =\\\n    {'max_depth': 20,\n     'max_features': 'sqrt',\n     'min_samples_leaf': 5,\n     'min_samples_split': 4,\n     'n_estimators': 150}\nrf = RandomForestRegressor(**chosen_params)\nrf.fit(X, y)\ny_test_pred = rf.predict(new_daily_test[features]) + new_daily_test['arima']\nnew_daily_test['Value_pred'] = y_test_pred\narimarf_rmse_daily = np.mean(np.sqrt((new_daily_test['Value'] - new_daily_test['Value_pred'])**2))\narima_rmse_daily = np.mean(np.sqrt((new_daily_test['Value'] - new_daily_test['arima'])**2))\n\n\nprint(f'ARIMA + RF on DAILY RMSE={arimarf_rmse_daily}')\nprint(f'ARIMA on DAILY RMSE={arima_rmse_daily}')\n'''\nIDEA: Hourly detrending instead of daily? - trend is almost daily mean.\nLong ARIMA (5,1,0) ?\nRNN to fit the hourly, 15 minute trend? \n'''\ntrend, seasonals, residuals = stl_decompose_plot(data_hourly.Value.dropna(), period=24)\n'''\nBest hourly arima (5,1,0) if max p = 5, huge ps when allowed higher. \nModel trend with some non linear models: RNN, TCN?\n'''\nhourly_trend_arima = auto_arima(trend.dropna(),\n                          information_criterion='bic',\n                          trace = True,\n                          stepwise = True,\n                          random_state=random_seed,\n                          max_p=4,\n                          max_d=2,\n                          max_q=4,\n                          n_fits = 100)\n# from statsmodels.tsa.seasonal import STL\n#\n# period = 96\n# res = STL(train.Value, period=period*7).fit()\n#\n# # %%\n# sns.set_palette(sns.color_palette(\"bright\", 6))\n# res.plot()\n# plt.show()\n'''\nBIC (5,2,2)\n'''\n\n# minute_trend_arima = auto_arima(res.trend,\n#                           information_criterion='aic',\n#                           trace = True,\n#                           stepwise = True,\n#                           random_state=random_seed,\n#                           max_p=5,\n#                           max_d=2,\n#                           max_q=5,\n#                           n_fits = 1000)", "params": {"random_seed": 1, "valid_from": "2021-11-01", "plots_path": "/home/m/repo/hydro-power-prediction/plots"}}