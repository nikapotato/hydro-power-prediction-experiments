{"timestamp": 1661328308.164391, "stored_source_code": "# Add description here\n#\n# *Note:* You can open this file as a notebook (JupyterLab: right-click on it in the side bar -> Open With -> Notebook)\n# Uncomment the next two lines to enable auto reloading for imported modules\n# %load_ext autoreload\n# %autoreload 2\n# For more info, see:\n# https://docs.ploomber.io/en/latest/user-guide/faq_index.html#auto-reloading-code-in-jupyter\n# If this task has dependencies, declare them in the YAML spec and leave this\n# as None\nimport re\nfrom pathlib import Path\nfrom pprint import pprint\n\nimport pandas as pd\nimport numpy as np\nfrom lightgbm import LGBMRegressor\nfrom matplotlib import pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.feature_selection import SelectFromModel, mutual_info_regression\nfrom sklearn.linear_model import RidgeCV, LassoCV, LinearRegression, Lasso, BayesianRidge, ARDRegression\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sktime.forecasting.model_selection import ExpandingWindowSplitter\n\nfrom hydro_timeseries.plotting import plot_fea_importance, get_windows\nfrom hydro_timeseries.util import load_timeseries_csv, smape, rmse, IdentityTransformer, select_kbest_features, \\\n    get_sample_weights\nfrom hydro_timeseries.variables import Variables\nimport seaborn as sns\nfrom collections import defaultdict\n\n\nupstream = None\n\n# This is a placeholder, leave it as None\nproduct = None\n\ndef read_auto_features(path: str) -> pd.DataFrame:\n    auto_features = pd.read_csv(path, parse_dates=['Unnamed: 0'], index_col='Unnamed: 0')\n    auto_features.index = pd.to_datetime(auto_features.index)\n    auto_features.index = auto_features.index.tz_localize(tz=None)\n    return auto_features\n'''\nAdd detrended target\n- include daily mean of the detrended target lagged by two days. \ndetrenders = ['arima_current', 'ets', 'exp', 'stl']\n'''\n# max_selected_features = 50\ndetrender = 'arima_current'\ntarget_new = 'value_detr'\nfeatures = load_timeseries_csv(upstream['feature-manual']['data'])\nvalue_detr = (features['Value'] - features[detrender]).dropna()\nfeatures = features.assign(value_detr = value_detr)\n\nfeatures['value_detr_daily_lag2'] = features[target_new].resample('D').mean().dropna().shift(2)\nfeatures['value_detr_daily_lag2'] = features['value_detr_daily_lag2'].ffill()\n\nplots_path = Path(plots_path)\nfeatures_meteo = read_auto_features(auto_meteo_features)\n# features_meteo = pd.read_csv(auto_meteo_features, parse_dates=['Unnamed: 0'], index_col='Unnamed: 0')\n# features_meteo.index = pd.to_datetime(features_meteo.index)\n# features_meteo.index = features_meteo.index.tz_localize(tz = None)\n\n\nsoil_moisture = features_meteo.filter(regex='.*moisture.*')\nprecip = features_meteo.filter(regex='.*precip.*')\npressure = features_meteo.filter(regex='.*pressure.*')\nsnow = features_meteo.filter(regex='.*snow.*')\ntranspiration = features_meteo.filter(regex='.*transpiration.*')\ndel features_meteo\n\nsoil_moisture_cols = soil_moisture.columns.to_list()\nprecip_cols = precip.columns.to_list()\npressure_cols = pressure.columns.to_list()\nsnow_cols = snow.columns.to_list()\ntranspiration_cols = transpiration.columns.to_list()\nfeatures_value_auto = read_auto_features(auto_value_features)\nvalue_cols = features_value_auto.columns.to_list()\nfeatures_concat = pd.concat([features, features_value_auto, soil_moisture, precip, pressure, snow, transpiration], axis=1)\nfeatures_new = features_concat[~features_concat['value_detr_daily_lag2'].isna() * ~features_concat['value_detr'].isna()]\nfeatures_new = features_new.dropna(axis = 1)\n# features_concat = features_concat.loc[~(features_concat['Value'] == 0), :]\n\ndel features_value_auto\n'''\nfeature_cols = value_cols + \\\n               snow_cols + \\\n               transpiration_cols + \\\n               pressure_cols + \\\n               precip_cols + \\\n               soil_moisture_cols + \\\n               Variables.cyclical_sin + \\\n               Variables.stl + \\\n               Variables.lagged + \\\n               Variables.meteo_ewms_hourly + \\\n               ['value_detr_daily_lag2']\n\n'''\n\nfeature_cols = value_cols + \\\n               snow_cols + \\\n               transpiration_cols + \\\n               pressure_cols + \\\n               precip_cols + \\\n               soil_moisture_cols + \\\n               Variables.cyclical_sin + \\\n               Variables.stl + \\\n               Variables.meteo_ewms_hourly + \\\n               Variables.meteo_i + \\\n               ['value_detr_daily_lag2']\nfeatures_train = features_new.iloc[:int(len(features_new) * 0.7)]\n\n# initial = Pipeline([\n#          ('scaler', StandardScaler()),\n#          ('selector', SelectFromModel(Lasso(alpha=0.1, max_iter=10000, tol=1e-3))),\n#          ('regressor', BayesianRidge(n_iter=10000))\n# ])\n\nvar_selector_model = Lasso(normalize=True, alpha=0.2, tol=1e-4)\n\n\nweights = get_sample_weights(features_train, daily_discount_rate)\n\nvar_selector_model.fit(features_train[feature_cols], features_train[target_new])\nvar_selector_model = var_selector_model.fit(features_train[feature_cols], features_train[target_new],sample_weight=weights)\nvar_selector = SelectFromModel(var_selector_model, prefit=True)\nfeatures_train_selected = var_selector.transform(features_train[feature_cols])\n\nselected_vars_ = features_train[feature_cols].columns[var_selector.get_support()].to_list()\npprint(selected_vars_)\n\n\n# selected_vars = ['val_sh2__agg_linear_trend__attr_rvalue__chunk_len_5__f_agg_min',\n#  'evapotranspiration_mean__quantile__q_01',\n#  'evapotranspiration_mean__variation_coefficient',\n#  'evapotranspiration_mean__permutation_entropy__dimension_6__tau_1',\n#  'pressure_mean__benford_correlation',\n#  'precip_mean__quantile__q_04',\n#  'soil_moisture_index_104',\n#  'soil_moisture_index_134',\n#  'daily_mean_precip_104_lag1',\n#  'daily_mean_precip_104_lag2',\n# ]\n\n# ['val_sh2__agg_linear_trend__attr_rvalue__chunk_len_5__f_agg_min',\n#  'val_sh2__linear_trend__attr_pvalue',\n#  'snow_mean__spkt_welch_density__coeff_2',\n#  'evapotranspiration_mean__quantile__q_01',\n#  'evapotranspiration_mean__variation_coefficient',\n#  'evapotranspiration_mean__permutation_entropy__dimension_6__tau_1',\n#  'pressure_mean__benford_correlation',\n#  'precip_mean__quantile__q_04',\n#  'precip_mean__change_quantiles__f_agg_var__isabs_True__qh_04__ql_02',\n#  'soil_moisture_mean__change_quantiles__f_agg_var__isabs_False__qh_08__ql_02',\n#  'soil_moisture_mean__ar_coefficient__coeff_6__k_10']\n\n\n'''\nRolling weekly cross val - monthly test set\n'''\n\nselected_vars = [\n 'stl_seasonal_lag2',\n 'soil_moisture_index_75',\n 'soil_moisture_index_104',\n 'soil_moisture_index_134',\n 'daily_mean_precip_104_lag1',\n 'daily_mean_precip_104_lag2',\n 'daily_mean_Value_lag2',\n 'soil_moisture_mean__ar_coefficient__coeff_3__k_10',\n 'snow_mean__large_standard_deviation__r_04',\n 'val_sh2__agg_linear_trend__attr_rvalue__chunk_len_5__f_agg_min'\n # 'precip_mean__median',\n # 'snow_mean__variance',\n # 'val_sh2__linear_trend__attr_pvalue',\n # 'val_sh2__agg_linear_trend__attr_rvalue__chunk_len_5__f_agg_min',\n # 'evapotranspiration_mean__variation_coefficient',\n # 'soil_moisture_mean__ar_coefficient__coeff_6__k_10',\n # 'pressure_mean__benford_correlation'\n]\n\nmonthly = 96*30\nweekly = 96*7\nfh_monthly = list(range(1, monthly))\n\nX_all = features_new[[target_new] + selected_vars].dropna()\ncv = ExpandingWindowSplitter(initial_window=int(len(X_all) * 0.7), step_length=weekly, fh=fh_monthly)\ntrain_windows, test_windows = get_windows(X_all, cv)\n\n\nmodels = {\n    'ridge': Pipeline([\n        ('scaler', StandardScaler()),\n        ('regressor', BayesianRidge(n_iter=3000))]),\n    'lasso': Pipeline([\n        ('scaler', StandardScaler()),\n        ('regressor', LassoCV(alphas=[1e-5, 1e-4, 1e-3, 1e-2, 1e-1], max_iter=10000))\n    ]),\n\n    'svm': Pipeline([\n        ('scaler', StandardScaler()),\n        ('regressor', LinearSVR(C=2.0, loss = 'squared_epsilon_insensitive', max_iter=10000))\n    ]),\n    'ardr': Pipeline([\n        ('scaler', StandardScaler()),\n        ('regressor', ARDRegression(n_iter=3000))\n    ]),\n    'nn': Pipeline([\n        ('scaler', StandardScaler()),\n        ('selector', PCA(n_components=4)),\n        ('regressor', MLPRegressor(hidden_layer_sizes=(32), alpha=5.0, early_stopping=True, learning_rate='adaptive'))]),\n\n    'dt': Pipeline([\n        ('scaler', StandardScaler()),\n        ('regressor', DecisionTreeRegressor(max_depth = 15, random_state=random_seed))]),\n    'exttree': Pipeline([\n        ('scaler', StandardScaler()),\n        ('regressor', ExtraTreesRegressor(n_estimators=30, max_depth=15, random_state=random_seed))]),\n    'lgbm': Pipeline([\n        ('scaler', StandardScaler()),\n        ('regressor', LGBMRegressor(n_estimators=30, max_depth=15, random_state=random_seed))]),\n}\n\nsmapes = defaultdict(list)\n\nfor fold_id, (train_ids, test_ids) in enumerate(cv.split(X_all)):\n    X_train = X_all.iloc[train_ids][selected_vars]\n    X_test = X_all.iloc[test_ids][selected_vars]\n    y_train = X_all.iloc[train_ids][target_new]\n    y_test = X_all.iloc[test_ids][target_new]\n\n    sample_weights = get_sample_weights(X_train, daily_discount_rate)\n\n    for key in models:\n        model = models[key]\n\n        if key == 'nn' or key == 'ardr' or key == 'gp':\n            model.fit(X_train, y_train)\n        else:\n            model.fit(X_train, y_train, regressor__sample_weight=sample_weights)\n\n        y_pred = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=[target_new])\n\n        # here to prevent column warning from sktime\n        value_pred = pd.DataFrame(features_new.loc[X_test.index][detrender] + y_pred[target_new], index=X_test.index, columns=['Value'])\n        value_true = features_new.loc[y_pred.index]['Value']\n\n        if not (value_pred.index == value_true.index).all():\n            print(\"break\")\n\n        smapes[key].append(smape(value_true, value_pred))\n\n    # add detrenders arima, autoets, stl for comparison\n    value_pred = features_new.loc[X_test.index]['arima_current']\n    value_true = features_new.loc[X_test.index]['Value']\n    smapes['arima_daily'].append(smape(value_true, value_pred))\n\n    value_pred = features_new.loc[X_test.index]['ets']\n    smapes['ets'].append(smape(value_true, value_pred))\n\n    value_pred = features_new.loc[X_test.index]['stl']\n    smapes['stl'].append(smape(value_true, value_pred))\n\nsmapes = pd.DataFrame().from_dict(smapes)\nbest_model = np.mean(smapes).idxmin()\n\nplt.figure(figsize=(10,5))\nsns.boxplot(data = smapes)\nax = plt.gca()\nax.set_title(f'Manual + auto features, SMAPE across n_folds={len(train_windows)}. Best: {best_model}, mean={np.mean(smapes[best_model]):.4f}')\nplt.savefig(plots_path / 'cv_auto.png')\nplt.show()\n\nprint(np.mean(smapes))", "params": {"random_seed": 1, "valid_from": "2021-11-01", "auto_meteo_features": "/home/m/repo/hydro-power-prediction/backup/critical/features_minute.csv", "auto_value_features": "/home/m/repo/hydro-power-prediction/backup/critical/features_daily_value.csv", "auto_meteo_daily_features": "/home/m/repo/hydro-power-prediction/backup/critical/features_daily.csv", "daily_discount_rate": 0.005, "plots_path": "/home/m/repo/hydro-power-prediction/plots"}}